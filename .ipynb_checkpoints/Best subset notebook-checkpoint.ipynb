{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an algorithm for best subset selection for linear regression using several selction criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from itertools import combinations\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the formulas for various selection criteria for the best subset in a linear regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total sum of squares, `SSTO`:\n",
    "$$\n",
    "SSTO = \\sum (Y_i - \\bar{Y})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error sum of squares, `SSE`:\n",
    "$$\n",
    "SSE = \\sum (Y_i - \\hat{Y_i})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression sum of squares, `SSR` (not used in calculations, but included for reference):  \n",
    "$$\n",
    "SSR = \\sum (\\hat{Y_i} - \\bar{Y})^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship between `SSTO`, `SSE`, and `SSR`:\n",
    "$$\n",
    "SSTO = SSE + SSR\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean squared error, `MSE`:\n",
    "$$\n",
    "MSE = \\frac{SSE}{n-2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `p` in the following formulas referes to the subset of `p` variables from the original set of independent variables. For example, if the original `X` has variables `x1`, `x2`, and `x3`, for `p=2`, `Xp` would be `{x1, x2}`, `{x1, x3}`, and `{x2, x3}`, and the criterions would be based on those subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coefficient of multiple determination, `R2`:\n",
    "$$\n",
    "R^{2}_p = 1 - \\frac{SSE_p}{SSTO}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjusted coefficient of multiple determination, `adj_R2`:  \n",
    "\n",
    "$$\n",
    "R^2_{a,p} = 1 - \\left(\\frac{n-1}{n-p}\\right)\\frac{SSE_p}{SSTO} = 1 - \\frac{MSE_p}{\\frac{SSTO}{n-1}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mallows's `Cp`:\n",
    "$$\n",
    "C_p = \\frac{SSE_p}{MSE(X_{1},...,X_{p-1})} - (n-2p)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions will calculate different statistical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSTO(y):\n",
    "    \n",
    "    '''Calculates sum of squares from the mean.'''\n",
    "    \n",
    "    y_mean = np.mean(y)\n",
    "    squared_errors = (y - y_mean)**2\n",
    "    \n",
    "    return np.sum(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SSE(y, predictions):\n",
    "    \n",
    "    '''Calculates sum of squared errors between predictions and actual values.'''\n",
    "    \n",
    "    squared_errors = (y - predictions)**2\n",
    "    \n",
    "    return np.sum(squared_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj_R2(_sse, _ssto, n, p):\n",
    "    \n",
    "    '''Calculates the adjusted R^2.'''\n",
    "    \n",
    "    return 1 - (n-1)/(n-p) * _sse/_ssto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cp(sse_p, sse_P, n, p, P):\n",
    "    \n",
    "    '''Calculates Mallows's Cp value. Needs sse_p and sse_P to be pre-calculated.'''\n",
    "    \n",
    "    return sse_p / (sse_P/(n-P)) - (n - 2*p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def AIC(_sse, n, p):\n",
    "    \n",
    "    '''Calculates the Akaike information criterion'''\n",
    "    \n",
    "    return n * np.log(_sse) - n * np.log(n) + 2*p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SBC(_sse, n, p):\n",
    "    \n",
    "    '''Calculates Schwarz Bayesian criterion'''\n",
    "    \n",
    "    return n * np.log(_sse) - n * np.log(n) + np.log(n) * p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRESS(X, y):\n",
    "    \n",
    "    '''Calculates PRESS criterion.'''\n",
    "    \n",
    "    lr = LinearRegression()\n",
    "    pred = np.zeros(y.shape)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        y_mod = np.delete(y, i, 0)\n",
    "        X_mod = np.delete(X, i, 0)\n",
    "        lr.fit(X_mod, y_mod)\n",
    "        pred[i] = lr.predict(X[i].reshape(1, -1))\n",
    "        \n",
    "    return SSE(y, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define some objects that will be needed in the main function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames that will store the best subset related information\n",
    "best_values_df = pd.DataFrame(columns = ['p', 'SSEp', 'R^2_p', 'Adj. R^2_p',\n",
    "                                         'Cp', 'AICp', 'SBCp', 'PRESSp'])\n",
    "best_subsets_df = pd.DataFrame(columns = ['p', 'SSEp', 'R^2_p', 'Adj. R^2_p',\n",
    "                                         'Cp', 'AICp', 'SBCp', 'PRESSp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the main function that will use the criterion calculations\n",
    "# to determine the best subsets for regression\n",
    "def get_subsets(X, y, P):\n",
    "    # make sure that both X and y are numpy arrays\n",
    "    if (type(X) != np.ndarray) or (type(y) != np.ndarray):\n",
    "        raise TypeError('X and y must be numpy arrays')\n",
    "    \n",
    "    # check to makes sure we have the same number of rows in X and y\n",
    "    if X.shape[0] != y.shape[0]:\n",
    "        raise ValueError('X and y must have the same number of rows')\n",
    "        \n",
    "    # set n as the number of observations\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    # create a range of values 1 through P for the numbers of variables in the subsets\n",
    "    P_range = range(1, P+1)\n",
    "    \n",
    "    # for both dataframes best_values_df and best_subsets_df,\n",
    "    # set values in the 'p' column to P_range values, and set that column as the index\n",
    "    best_values_df['p'] = P_range\n",
    "    best_values_df.set_index('p', inplace = True)\n",
    "    best_subsets_df['p'] = P_range\n",
    "    best_subsets_df.set_index('p', inplace = True)\n",
    "    \n",
    "    # create subsets of X consisting of 1 through P variables\n",
    "    # first, create an empty list to hold the tuples of subsets\n",
    "    X_subsets = []\n",
    "    \n",
    "    # create combinations of subsets using the 'combinations' function\n",
    "    # and iterating over values in range equal to the number of X variables\n",
    "    for i in range(1, P):\n",
    "        combs = combinations(range(X.shape[1]), i)\n",
    "        for item in combs:\n",
    "            X_subsets.append(item)\n",
    "            \n",
    "    # create intermediate dataframes to hold criterion values\n",
    "    SSE_df = pd.DataFrame(columns=['X_var', 'p', 'SSEp'])\n",
    "    SSE_df.set_index('X_var')\n",
    "    R2_df = pd.DataFrame(columns=['X_var', 'p', 'R2p'])\n",
    "    adj_R2_df = pd.DataFrame(columns=['X_var', 'p', 'adj_R2p'])\n",
    "    C_df = pd.DataFrame(columns=['X_var', 'p', 'Cp', 'Abs_Cp'])\n",
    "    AIC_df = pd.DataFrame(columns=['X_var', 'p', 'AICp'])\n",
    "    SBC_df = pd.DataFrame(columns=['X_var', 'p', 'SBCp'])\n",
    "    PRESS_df = pd.DataFrame(columns=['X_var', 'p', 'PRESSp'])\n",
    "    \n",
    "    # calculate SSTO for y\n",
    "    # SSTO will be the same for any subset of X (look at the formula above for details)\n",
    "    _ssto = SSTO(y)\n",
    "    \n",
    "    # Scikit-learn linear regression used in calculations\n",
    "    lin_reg = LinearRegression()\n",
    "    \n",
    "    # populate SSE, R2, adj_R2, AIC, and SBC values in the respective dataframes\n",
    "    for i in P_range:\n",
    "        # p = 1 means using just the constant with no subset of X.\n",
    "        # Hence, all entries for X_var are 'None'.\n",
    "        if i == 1:\n",
    "            _sse = _ssto\n",
    "            SSE_df.loc['None'] = ['None', i, _sse]\n",
    "            R2_df.loc['None'] = ['None', i, 0]\n",
    "            adj_R2_df.loc['None'] = ['None', i, 0]\n",
    "            AIC_df.loc['None'] = ['None', i, AIC(_sse, n, i)]\n",
    "            SBC_df.loc['None'] = ['None', i, SBC(_sse, n, i)]\n",
    "        else:\n",
    "            # get only subsets that consist only of i-1 variables\n",
    "            current_subset = [item for item in X_subsets if len(item) == i-1]\n",
    "            # calculate criterions for the current_subset\n",
    "            for item in current_subset:\n",
    "                # fit linear regression to the current subset\n",
    "                # and use it for predict values when needed\n",
    "                lin_reg.fit(X[:, item], y)\n",
    "                y_hat = lin_reg.predict(X[:, item])\n",
    "                # create var numbers (X1, X2, etc) for dataframe display\n",
    "                var_numbers = [f'X{num + 1}' for num in item]\n",
    "                # populate SSE_df\n",
    "                _sse = SSE(y, y_hat)\n",
    "                # convert the list of var_numbers into a single string to use for indexing\n",
    "                # e.g. a list of ['X1', 'X2'] turns into a string \"['X1', 'X2']\"\n",
    "                # which can be used a single label\n",
    "                SSE_df.loc[str(var_numbers)] = [var_numbers, i, _sse]\n",
    "                # populate R2_df using scikit-learn's 'score' method\n",
    "                R2_df.loc[str(var_numbers)] = [var_numbers, i, lin_reg.score(X[:, item], y)]\n",
    "                # populate the adj_R2, AIC, and SBC dataframes\n",
    "                adj_R2_df.loc[str(var_numbers)] = [var_numbers, i, adj_R2(_sse, _ssto, n, i)]\n",
    "                AIC_df.loc[str(var_numbers)] = [var_numbers, i, AIC(_sse, n, i)]\n",
    "                SBC_df.loc[str(var_numbers)] = [var_numbers, i, SBC(_sse, n, i)]\n",
    "                \n",
    "    display(R2_df.dtypes)\n",
    "    # Calculate Cp values and populate C_df\n",
    "    for i in P_range:\n",
    "        if i == 1:\n",
    "            # get SSEp value for the the whole set of variables\n",
    "            # which can be extracted from SSE_df using the last var_numbers values\n",
    "            sse_P = SSE_df.loc[str(var_numbers)].SSEp\n",
    "                \n",
    "            # calculate Cp values using sse_P and _ssto\n",
    "            # (_ssto is used in place of sse_p since \n",
    "            # we're not using a subset of X for this specific calculation)\n",
    "            Cp_val = Cp(_ssto, sse_P, n, i, P)\n",
    "                \n",
    "            # enter the value into C_df\n",
    "            #TODO: why is it 'abs(Cp_val - i)'?\n",
    "            C_df.loc['None'] = ['None', i, Cp_val, abs(Cp_val - i)]\n",
    "        else:\n",
    "            current_subset = [item for item in X_subsets if len(item) == i - 1]\n",
    "            for x in current_subset:\n",
    "                # create variable names such as 'X1', 'X2', etc\n",
    "                c_var_numbers = [f'X{num+1}' for num in x]\n",
    "                    \n",
    "                # get the _sse value for the current var number\n",
    "                _sse = SSE_df.loc[str(c_var_numbers)].SSEp\n",
    "                    \n",
    "                # calculate Cp value\n",
    "                Cp_val = Cp(_sse, sse_P, n, i, P)\n",
    "                    \n",
    "                # populate C_df; #TODO: why 'abs(Cp_val - i)'?\n",
    "                C_df.loc[str(c_var_numbers)] = [c_var_numbers, i, Cp_val, abs(Cp_val - i)]\n",
    "                    \n",
    "    # calculate PRESSp and populate PRESS_df\n",
    "    PRESS_predictions = np.zeros(y.shape)\n",
    "    for i in P_range:\n",
    "        if i == 1:\n",
    "            for j in range(X.shape[0]):\n",
    "                # delete a set of y values to be replaced by predictions\n",
    "                y_mod = np.delete(y, j, 0)\n",
    "                # in case of no X variables (P=1), use the mean as the prediction\n",
    "                PRESS_predictions[j] = np.mean(y_mod)\n",
    "            PRESS_df.loc['None'] = ['None', i, SSE(y, PRESS_predictions)]\n",
    "        else:\n",
    "            current_subset = [item for item in X_subsets if len(item) == i-1]\n",
    "            for x in current_subset:\n",
    "                PRESS_var_numbers = [f'X{num+1}' for num in x]\n",
    "                PRESS_df.loc[str(PRESS_var_numbers)] = [PRESS_var_numbers, i,\n",
    "                                                        PRESS(X[:,x], y)]\n",
    "                    \n",
    "    for i in P_range:\n",
    "        best_values_df.loc[i, 'SSEp'] = SSE_df[SSE_df.p == i].min().SSEp\n",
    "        best_subsets_df.loc[i, 'SSEp'] = SSE_df[SSE_df.p == i].SSEp.idxmin()\n",
    "        best_values_df.loc[i, 'R^2_p'] = R2_df[R2_df.p == i].max().R2p\n",
    "        best_subsets_df.loc[i, 'R^2_p'] = R2_df[R2_df.p == i].R2p.idxmax()\n",
    "        best_values_df.loc[i, 'Adj_R^2_p'] = adj_R2_df[adj_R2_df.p == i].max().adj_R2p\n",
    "        best_subsets_df.loc[i, 'Adj_R^2_p'] = adj_R2_df[adj_R2_df.p == i].adj_R2p.idxmax()\n",
    "        best_values_df.loc[i, 'Cp'] = C_df[C_df.p == i].min().Cp\n",
    "        best_subsets_df.loc[i, 'Cp'] = C_df[C_df.p == i].Abs_Cp.idxmin()\n",
    "        best_values_df.loc[i, 'AICp'] = AIC_df[AIC_df.p == i].min().AICp\n",
    "        best_subsets_df.loc[i, 'AICp'] = AIC_df[AIC_df.p == i].AICp.idxmin()\n",
    "        best_values_df.loc[i, 'SBCp'] = SBC_df[SBC_df.p == i].min().SBCp\n",
    "        best_subsets_df.loc[i, 'SBCp'] = SBC_df[SBC_df.p == i].SBCp.idxmin()\n",
    "        best_values_df.loc[i, 'PRESSp'] = PRESS_df[PRESS_df.p == i].min().PRESSp\n",
    "        best_subsets_df.loc[i, 'PRESSp'] = PRESS_df[PRESS_df.p == i].PRESSp.idxmin()\n",
    "        \n",
    "    display('Best Values for Criteria')\n",
    "    display(best_values_df)\n",
    "    print('\\n')\n",
    "    display('Best Subsets for Criteria')\n",
    "    display(best_subsets_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.7     62.      81.       2.59    50.       0.       1.       0.\n",
      "   695.       6.544]\n",
      " [   5.1     59.      66.       1.7     39.       0.       0.       0.\n",
      "   403.       5.999]\n",
      " [   7.4     57.      83.       2.16    55.       0.       0.       0.\n",
      "   710.       6.565]\n",
      " [   6.5     73.      41.       2.01    48.       0.       0.       0.\n",
      "   349.       5.854]\n",
      " [   7.8     65.     115.       4.3     45.       0.       0.       1.\n",
      "  2343.       7.759]\n",
      " [   5.8     38.      72.       1.42    65.       1.       1.       0.\n",
      "   348.       5.852]\n",
      " [   5.7     46.      63.       1.91    49.       1.       0.       1.\n",
      "   518.       6.25 ]\n",
      " [   3.7     68.      81.       2.57    69.       1.       1.       0.\n",
      "   749.       6.619]\n",
      " [   6.      67.      93.       2.5     58.       0.       1.       0.\n",
      "  1056.       6.962]\n",
      " [   3.7     76.      94.       2.4     48.       0.       1.       0.\n",
      "   968.       6.875]\n",
      " [   6.3     84.      83.       4.13    37.       0.       1.       0.\n",
      "   745.       6.613]\n",
      " [   6.7     51.      43.       1.86    57.       0.       1.       0.\n",
      "   257.       5.549]\n",
      " [   5.8     96.     114.       3.95    63.       1.       0.       0.\n",
      "  1573.       7.361]\n",
      " [   5.8     83.      88.       3.95    52.       1.       0.       0.\n",
      "   858.       6.754]\n",
      " [   7.7     62.      67.       3.4     58.       0.       0.       1.\n",
      "   702.       6.554]\n",
      " [   7.4     74.      68.       2.4     64.       1.       1.       0.\n",
      "   809.       6.695]\n",
      " [   6.      85.      28.       2.98    36.       1.       1.       0.\n",
      "   682.       6.526]\n",
      " [   3.7     51.      41.       1.55    39.       0.       0.       0.\n",
      "   205.       5.321]\n",
      " [   7.3     68.      74.       3.56    59.       1.       0.       0.\n",
      "   550.       6.309]\n",
      " [   5.6     57.      87.       3.02    63.       0.       0.       1.\n",
      "   838.       6.731]\n",
      " [   5.2     52.      76.       2.85    39.       0.       0.       0.\n",
      "   359.       5.883]\n",
      " [   3.4     83.      53.       1.12    67.       1.       1.       0.\n",
      "   353.       5.866]\n",
      " [   6.7     26.      68.       2.1     30.       0.       0.       1.\n",
      "   599.       6.395]\n",
      " [   5.8     67.      86.       3.4     49.       1.       1.       0.\n",
      "   562.       6.332]\n",
      " [   6.3     59.     100.       2.95    36.       1.       1.       0.\n",
      "   651.       6.478]\n",
      " [   5.8     61.      73.       3.5     62.       1.       1.       0.\n",
      "   751.       6.621]\n",
      " [   5.2     52.      86.       2.45    70.       0.       1.       0.\n",
      "   545.       6.302]\n",
      " [  11.2     76.      90.       5.59    58.       1.       0.       1.\n",
      "  1965.       7.583]\n",
      " [   5.2     54.      56.       2.71    44.       1.       0.       0.\n",
      "   477.       6.167]\n",
      " [   5.8     76.      59.       2.58    61.       1.       1.       0.\n",
      "   600.       6.396]\n",
      " [   3.2     64.      65.       0.74    53.       0.       1.       0.\n",
      "   443.       6.094]\n",
      " [   8.7     45.      23.       2.52    68.       0.       1.       0.\n",
      "   181.       5.198]\n",
      " [   5.      59.      73.       3.5     57.       0.       1.       0.\n",
      "   411.       6.019]\n",
      " [   5.8     72.      93.       3.3     39.       1.       0.       1.\n",
      "  1037.       6.944]\n",
      " [   5.4     58.      70.       2.64    31.       1.       1.       0.\n",
      "   482.       6.179]\n",
      " [   5.3     51.      99.       2.6     48.       0.       1.       0.\n",
      "   634.       6.453]\n",
      " [   2.6     74.      86.       2.05    45.       0.       0.       0.\n",
      "   678.       6.519]\n",
      " [   4.3      8.     119.       2.85    65.       1.       0.       0.\n",
      "   362.       5.893]\n",
      " [   4.8     61.      76.       2.45    51.       1.       1.       0.\n",
      "   637.       6.457]\n",
      " [   5.4     52.      88.       1.81    40.       1.       0.       0.\n",
      "   705.       6.558]\n",
      " [   5.2     49.      72.       1.84    46.       0.       0.       0.\n",
      "   536.       6.283]\n",
      " [   3.6     28.      99.       1.3     55.       0.       0.       1.\n",
      "   582.       6.366]\n",
      " [   8.8     86.      88.       6.4     30.       1.       1.       0.\n",
      "  1270.       7.147]\n",
      " [   6.5     56.      77.       2.85    41.       0.       1.       0.\n",
      "   538.       6.288]\n",
      " [   3.4     77.      93.       1.48    69.       0.       1.       0.\n",
      "   482.       6.178]\n",
      " [   6.5     40.      84.       3.      54.       1.       1.       0.\n",
      "   611.       6.416]\n",
      " [   4.5     73.     106.       3.05    47.       1.       1.       0.\n",
      "   960.       6.867]\n",
      " [   4.8     86.     101.       4.1     35.       1.       0.       1.\n",
      "  1300.       7.17 ]\n",
      " [   5.1     67.      77.       2.86    66.       1.       0.       0.\n",
      "   581.       6.365]\n",
      " [   3.9     82.     103.       4.55    50.       0.       1.       0.\n",
      "  1078.       6.983]\n",
      " [   6.6     77.      46.       1.95    50.       0.       1.       0.\n",
      "   405.       6.005]\n",
      " [   6.4     85.      40.       1.21    58.       0.       0.       1.\n",
      "   579.       6.361]\n",
      " [   6.4     59.      85.       2.33    63.       0.       1.       0.\n",
      "   550.       6.31 ]\n",
      " [   8.8     78.      72.       3.2     56.       0.       0.       0.\n",
      "   651.       6.478]]\n"
     ]
    }
   ],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "data = np.loadtxt('Surgical Data.txt')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   6.7    62.     81.      2.59   50.      0.      1.      0.    695.  ]\n",
      " [   5.1    59.     66.      1.7    39.      0.      0.      0.    403.  ]\n",
      " [   7.4    57.     83.      2.16   55.      0.      0.      0.    710.  ]\n",
      " [   6.5    73.     41.      2.01   48.      0.      0.      0.    349.  ]\n",
      " [   7.8    65.    115.      4.3    45.      0.      0.      1.   2343.  ]\n",
      " [   5.8    38.     72.      1.42   65.      1.      1.      0.    348.  ]\n",
      " [   5.7    46.     63.      1.91   49.      1.      0.      1.    518.  ]\n",
      " [   3.7    68.     81.      2.57   69.      1.      1.      0.    749.  ]\n",
      " [   6.     67.     93.      2.5    58.      0.      1.      0.   1056.  ]\n",
      " [   3.7    76.     94.      2.4    48.      0.      1.      0.    968.  ]\n",
      " [   6.3    84.     83.      4.13   37.      0.      1.      0.    745.  ]\n",
      " [   6.7    51.     43.      1.86   57.      0.      1.      0.    257.  ]\n",
      " [   5.8    96.    114.      3.95   63.      1.      0.      0.   1573.  ]\n",
      " [   5.8    83.     88.      3.95   52.      1.      0.      0.    858.  ]\n",
      " [   7.7    62.     67.      3.4    58.      0.      0.      1.    702.  ]\n",
      " [   7.4    74.     68.      2.4    64.      1.      1.      0.    809.  ]\n",
      " [   6.     85.     28.      2.98   36.      1.      1.      0.    682.  ]\n",
      " [   3.7    51.     41.      1.55   39.      0.      0.      0.    205.  ]\n",
      " [   7.3    68.     74.      3.56   59.      1.      0.      0.    550.  ]\n",
      " [   5.6    57.     87.      3.02   63.      0.      0.      1.    838.  ]\n",
      " [   5.2    52.     76.      2.85   39.      0.      0.      0.    359.  ]\n",
      " [   3.4    83.     53.      1.12   67.      1.      1.      0.    353.  ]\n",
      " [   6.7    26.     68.      2.1    30.      0.      0.      1.    599.  ]\n",
      " [   5.8    67.     86.      3.4    49.      1.      1.      0.    562.  ]\n",
      " [   6.3    59.    100.      2.95   36.      1.      1.      0.    651.  ]\n",
      " [   5.8    61.     73.      3.5    62.      1.      1.      0.    751.  ]\n",
      " [   5.2    52.     86.      2.45   70.      0.      1.      0.    545.  ]\n",
      " [  11.2    76.     90.      5.59   58.      1.      0.      1.   1965.  ]\n",
      " [   5.2    54.     56.      2.71   44.      1.      0.      0.    477.  ]\n",
      " [   5.8    76.     59.      2.58   61.      1.      1.      0.    600.  ]\n",
      " [   3.2    64.     65.      0.74   53.      0.      1.      0.    443.  ]\n",
      " [   8.7    45.     23.      2.52   68.      0.      1.      0.    181.  ]\n",
      " [   5.     59.     73.      3.5    57.      0.      1.      0.    411.  ]\n",
      " [   5.8    72.     93.      3.3    39.      1.      0.      1.   1037.  ]\n",
      " [   5.4    58.     70.      2.64   31.      1.      1.      0.    482.  ]\n",
      " [   5.3    51.     99.      2.6    48.      0.      1.      0.    634.  ]\n",
      " [   2.6    74.     86.      2.05   45.      0.      0.      0.    678.  ]\n",
      " [   4.3     8.    119.      2.85   65.      1.      0.      0.    362.  ]\n",
      " [   4.8    61.     76.      2.45   51.      1.      1.      0.    637.  ]\n",
      " [   5.4    52.     88.      1.81   40.      1.      0.      0.    705.  ]\n",
      " [   5.2    49.     72.      1.84   46.      0.      0.      0.    536.  ]\n",
      " [   3.6    28.     99.      1.3    55.      0.      0.      1.    582.  ]\n",
      " [   8.8    86.     88.      6.4    30.      1.      1.      0.   1270.  ]\n",
      " [   6.5    56.     77.      2.85   41.      0.      1.      0.    538.  ]\n",
      " [   3.4    77.     93.      1.48   69.      0.      1.      0.    482.  ]\n",
      " [   6.5    40.     84.      3.     54.      1.      1.      0.    611.  ]\n",
      " [   4.5    73.    106.      3.05   47.      1.      1.      0.    960.  ]\n",
      " [   4.8    86.    101.      4.1    35.      1.      0.      1.   1300.  ]\n",
      " [   5.1    67.     77.      2.86   66.      1.      0.      0.    581.  ]\n",
      " [   3.9    82.    103.      4.55   50.      0.      1.      0.   1078.  ]\n",
      " [   6.6    77.     46.      1.95   50.      0.      1.      0.    405.  ]\n",
      " [   6.4    85.     40.      1.21   58.      0.      0.      1.    579.  ]\n",
      " [   6.4    59.     85.      2.33   63.      0.      1.      0.    550.  ]\n",
      " [   8.8    78.     72.      3.2    56.      0.      0.      0.    651.  ]]\n",
      "[6.544 5.999 6.565 5.854 7.759 5.852 6.25  6.619 6.962 6.875 6.613 5.549\n",
      " 7.361 6.754 6.554 6.695 6.526 5.321 6.309 6.731 5.883 5.866 6.395 6.332\n",
      " 6.478 6.621 6.302 7.583 6.167 6.396 6.094 5.198 6.019 6.944 6.179 6.453\n",
      " 6.519 5.893 6.457 6.558 6.283 6.366 7.147 6.288 6.178 6.416 6.867 7.17\n",
      " 6.365 6.983 6.005 6.361 6.31  6.478]\n"
     ]
    }
   ],
   "source": [
    "data_x = data[:,:-1]\n",
    "data_y = data[:, -1]\n",
    "print(data_x)\n",
    "print(data_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X_var    object\n",
       "p        object\n",
       "R2p      object\n",
       "dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "reduction operation 'argmax' not allowed for this dtype",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-453744236177>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_subsets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-77fe19ec0ac3>\u001b[0m in \u001b[0;36mget_subsets\u001b[1;34m(X, y, P)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[0mbest_subsets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'SSEp'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSSE_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mSSE_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSSEp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \u001b[0mbest_values_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'R^2_p'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR2_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mR2_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR2p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[0mbest_subsets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'R^2_p'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mR2_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mR2_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mR2p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m         \u001b[0mbest_values_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Adj_R^2_p'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madj_R2_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0madj_R2_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj_R2p\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mbest_subsets_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Adj_R^2_p'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madj_R2_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0madj_R2_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mp\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madj_R2p\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36midxmax\u001b[1;34m(self, axis, skipna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2166\u001b[0m         \"\"\"\n\u001b[0;32m   2167\u001b[0m         \u001b[0mskipna\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidate_argmax_with_skipna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2168\u001b[1;33m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnanops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnanargmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2169\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2170\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobj_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0mf_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nan\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m                 raise TypeError(\n\u001b[0m\u001b[0;32m     67\u001b[0m                     \u001b[1;34mf\"reduction operation '{f_name}' not allowed for this dtype\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                 )\n",
      "\u001b[1;31mTypeError\u001b[0m: reduction operation 'argmax' not allowed for this dtype"
     ]
    }
   ],
   "source": [
    "get_subsets(data_x, data_y, 9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
